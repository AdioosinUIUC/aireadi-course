{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "X8ZLRuine7ay"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial demonstrates an end-to-end **Image Classification** pipeline using PyTorch and a **ResNet-50** deep learning model. The goal is to **classify Retinal Fundus Photographs** into different **device categories** based on their acquisition source. These images are labeled with metadata that includes the device type and diabetic severity level.\n",
    "\n",
    "Key steps in the workflow include:\n",
    "\n",
    "1. **Environment Setup**: Installing required libraries and getting access to dataset.\n",
    "\n",
    "2. **Introduction to the problem**: Load and view example images from the dataset.\n",
    "\n",
    "3. **Data Preparation**: Extracting image files, reading associated labels from a TSV file, and splitting the dataset into training, validation, and test sets.\n",
    "\n",
    "4. **Custom Dataset Creation**: Defining a PyTorch Dataset class to load and transform images.  Applying normalization, and data augmentation techniques.  Loading data into memory for use.\n",
    "\n",
    "5. **Model Building**: Loading a pre-defined ResNet-50 architecture and modifying its output layer for our custom classification task.  Set training parameters.\n",
    "\n",
    "6. **Training & Validation**: Training the model using cross-entropy loss, tracking loss and accuracy over epochs, and visualizing performance.\n",
    "\n",
    "7. **Prediction on Validation Data**: Evaluating model accuracy on validation data.\n",
    "\n",
    "8. **Result Analysis**: Generating and displaying confusion matrices and plotting ROC curves for validation data.\n",
    "\n",
    "9. **Try to Make the Model Perform Better**: Try a different optimizer and model initialization to improve performance.\n",
    "\n",
    "10. **Chose a Model to Evaludate on Test Data**:  The test set should be reserved for when you have chosen a final model.  You cannot change your model after this point without creating a new test set.\n",
    "\n",
    "11. **Explore the effect of hyperparameters in a sandbox.**\n",
    "\n",
    "This tutorial is designed to help you understand the workflow of building a robust image classifier using real-world medical image data, along with visual performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "eB8YOlJhUjln"
   },
   "source": [
    "## 1. Environment Setup: Importing Required Libraries\n",
    "**Loading essential libraries for data processing, model training, and evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "5330d28b-84ed-4738-9ed1-5a1b8be24f9c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Set CUBLAS workspace configuration before any CUDA-related imports\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "start_total = time.time()\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "i9ox1_JfUtV3"
   },
   "source": [
    "## 2. Introduction to the problem: Load and view example images from the dataset.\n",
    "**2a) Problem: Classify device from cropped, grayscale CFP images**\n",
    "\n",
    "We have CFP images from 4 devices: iCare Eidon, Topcon Maestro2, Topcon Triton, and Optomed Aurora.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "i9ox1_JfUtV3",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2b) We can load an image for one participant/eye and view.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_eidon = np.asarray(Image.open('APPFL/examples/full/icare_eidon/1270_eidon_uwf_central_cfp_r_1.2.826.0.1.3680043.8.641.1.20240510.232115.43583.jpg'))\n",
    "img_maestro = np.asarray(Image.open('APPFL/examples/full/topcon_maestro2/1270_maestro2_3d_macula_cfp_r_2.16.840.1.114517.10.5.1.4.907063120240510160806.2.1.jpg'))\n",
    "img_triton = np.asarray(Image.open('APPFL/examples/full/topcon_triton/1274_triton_macula_12x12_cfp_r_2.16.840.1.114517.10.5.1.4.94005520240514143050.2.1.jpg'))\n",
    "img_optomed = np.asarray(Image.open('APPFL/examples/full/optomed_aurora/1270_optomed_mac_or_disk_centered_cfp_r_2.25.2183161925995491838121778870991254610818.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,50))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(img_eidon)\n",
    "plt.title('iCare Eidon')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(img_maestro)\n",
    "plt.title('Topcon Maestro2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(img_triton)\n",
    "plt.title('Topcon Triton')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(img_optomed)\n",
    "plt.title('Optomed Aurora')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "i9ox1_JfUtV3"
   },
   "source": [
    "**2c) Create a function to convert the full RGB images to cropped, grayscale images and convert the loaded images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gs(image):\n",
    "    img_array = np.array(image)\n",
    "    h, w, _ = img_array.shape\n",
    "    top = (h - 224) // 2\n",
    "    left = (w - 224) // 2\n",
    "    center_crop = img_array[top:top+224, left:left+224]\n",
    "    gray = np.dot(center_crop[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_eidon_gs = rgb2gs(img_eidon)\n",
    "img_maestro_gs = rgb2gs(img_maestro)\n",
    "img_triton_gs = rgb2gs(img_triton)\n",
    "img_optomed_gs = rgb2gs(img_optomed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "i9ox1_JfUtV3"
   },
   "source": [
    "**2d) Plot cropped, grayscale images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,50))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(img_eidon_gs,cmap='gray')\n",
    "plt.title('iCare Eidon')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(img_maestro_gs,cmap='gray')\n",
    "plt.title('Topcon Maestro2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(img_triton_gs,cmap='gray')\n",
    "plt.title('Topcon Triton')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(img_optomed_gs,cmap='gray')\n",
    "plt.title('Optomed Aurora')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "i9ox1_JfUtV3"
   },
   "source": [
    "**2e) Load all images for participant, convert to cropped grayscale and plot all the full RGB and cropped, grayscale images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = '1270' #if you want to look at a different set of participant images change the \"1270\" to another number 1000-1300\n",
    "\n",
    "#load image arrays and device name into a dictionary for plotting\n",
    "img_dict = {}\n",
    "for f in glob.glob('APPFL/examples/full/icare_eidon/' + patient_id + '*'):\n",
    "    img_dict[f] = {}\n",
    "    img_dict[f]['img'] = np.asarray(Image.open(f).resize((224, 224)))\n",
    "    img_dict[f]['device'] = 'icare_eidon'\n",
    "for f in glob.glob('APPFL/examples/full/topcon_maestro2/' + patient_id + '*'):\n",
    "    img_dict[f] = {}\n",
    "    img_dict[f]['img'] = np.asarray(Image.open(f).resize((224, 224)))\n",
    "    img_dict[f]['device'] = 'topcon_maestro2'\n",
    "for f in glob.glob('APPFL/examples/full/topcon_triton/' + patient_id + '*'):\n",
    "    img_dict[f] = {}\n",
    "    img_dict[f]['img'] = np.asarray(Image.open(f).resize((224, 224)))\n",
    "    img_dict[f]['device'] = 'topcon_triton'\n",
    "for f in glob.glob('APPFL/examples/full/optomed_aurora/' + patient_id + '*'):\n",
    "    img_dict[f] = {}\n",
    "    img_dict[f]['img'] = np.asarray(Image.open(f).resize((224, 224)))\n",
    "    img_dict[f]['device'] = 'optomed_aurora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the keys of the dictionary and randomize\n",
    "keys = list(img_dict.keys())\n",
    "random.shuffle(keys)\n",
    "\n",
    "#plot without titles\n",
    "plt.figure(figsize=(10,10))\n",
    "n=1\n",
    "for k in keys:\n",
    "    plt.subplot(5,5,n)\n",
    "    plt.imshow(img_dict[k]['img'])\n",
    "    plt.axis('off')\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n=1\n",
    "for k in keys:\n",
    "    plt.subplot(5,5,n)\n",
    "    plt.imshow(img_dict[k]['img'])\n",
    "    plt.title(img_dict[k]['device'])\n",
    "    plt.axis('off')\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load add cropped, grayscale image arrays and device name into a dictionary for plotting\n",
    "for f in glob.glob('APPFL/examples/full/icare_eidon/' + patient_id + '*'):\n",
    "    img_dict[f]['img_gs'] = rgb2gs(np.asarray(Image.open(f)))\n",
    "for f in glob.glob('APPFL/examples/full/topcon_maestro2/' + patient_id + '*'):\n",
    "    img_dict[f]['img_gs'] = rgb2gs(np.asarray(Image.open(f)))\n",
    "for f in glob.glob('APPFL/examples/full/topcon_triton/' + patient_id + '*'):\n",
    "    img_dict[f]['img_gs'] = rgb2gs(np.asarray(Image.open(f)))\n",
    "for f in glob.glob('APPFL/examples/full/optomed_aurora/' + patient_id + '*'):\n",
    "    img_dict[f]['img_gs'] = rgb2gs(np.asarray(Image.open(f)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n=1\n",
    "for k in keys:\n",
    "    plt.subplot(5,5,n)\n",
    "    plt.imshow(img_dict[k]['img_gs'],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n=1\n",
    "for k in keys:\n",
    "    plt.subplot(5,5,n)\n",
    "    plt.imshow(img_dict[k]['img_gs'],cmap='gray')\n",
    "    plt.title(img_dict[k]['device'])\n",
    "    plt.axis('off')\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "i9ox1_JfUtV3"
   },
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "**3a) Loading Dataset Labels**: We read the labels from a TSV file, which contains metadata about images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "fb73f0e3-4d41-403c-a18a-92d30dc24b80",
    "outputId": "73b97992-03a5-4544-d0d3-dd1ad62d49e3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing data label\n",
    "tsv_path = \"APPFL/examples/cfp_images/labels.tsv\"\n",
    "df = pd.read_csv(tsv_path, sep='\\t')\n",
    "\n",
    "# printing top 5\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the first 20 lines\n",
    "print(df[['subject_id','device','partition']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "JoiFJ3UYU136"
   },
   "source": [
    "**3b) Splitting Dataset**: The dataset is split into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a60fdde-b703-493f-aa1d-b9b2d2d3ed33",
    "outputId": "ec299809-dcef-495f-fdfb-0822b2f75296",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dividing data into diffrent dataframes based on train, validation and test\n",
    "train_df = df[df[\"partition\"] == \"train\"].copy()\n",
    "val_df   = df[df[\"partition\"] == \"val\"].copy()\n",
    "test_df  = df[df[\"partition\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Number of data sample \\nTraining\", len(train_df), \"\\nValidation\", len(val_df), \"\\nTest\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59ec4dfe-156a-44c4-a9d4-4c0fd7e2943c",
    "outputId": "02425da4-d1a9-46a8-ad92-d8008fb3b838",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding unique classes and giving it a number index\n",
    "# in this case we have 4 classes\n",
    "unique_classes = sorted(train_df[\"device\"].unique())\n",
    "\n",
    "# Mapping classes to a particular index\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(unique_classes)}\n",
    "print(\"Class to index mapping:\", class_to_idx)\n",
    "\n",
    "train_df[\"label_idx\"] = train_df[\"device\"].map(class_to_idx)\n",
    "val_df[\"label_idx\"]   = val_df[\"device\"].map(class_to_idx)\n",
    "test_df[\"label_idx\"]  = test_df[\"device\"].map(class_to_idx)\n",
    "\n",
    "num_classes = len(unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "JoiFJ3UYU136"
   },
   "source": [
    "**3c) Distribution of the Labels**:We can plot the distribution of the labels across the three partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = sorted(train_df[\"device\"])\n",
    "_ = plt.hist(train_labels)\n",
    "plt.title('train distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = sorted(val_df[\"device\"])\n",
    "_ = plt.hist(val_labels)\n",
    "plt.title('val distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = sorted(test_df[\"device\"])\n",
    "_ = plt.hist(test_labels)\n",
    "plt.title('test distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "0wLvKQOKVNKr"
   },
   "source": [
    "## 4. Defining the Custom Dataset Class\n",
    "\n",
    "**4a) This class is used for loading images (cropping and converting to grayscale) and applying transformations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "d87412c0-2dec-4d53-9b73-4747c1867838",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a dataloader class, which returns image and its label\n",
    "class AIREADIDataset_grayscalecrop(Dataset):\n",
    "    def __init__(self, df, transform=None, preload=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          df: a DataFrame with at least ['file_path', 'label_idx'] columns\n",
    "          transform: torchvision transforms (augmentations) to apply\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.preload = []\n",
    "        if preload:\n",
    "            partition = self.df[\"partition\"][0]\n",
    "            npsavfn = f\"APPFL/examples/cfp_images/graycrop-{partition}.npy\"\n",
    "            if os.path.isfile(npsavfn):\n",
    "                self.preload = np.load(npsavfn)\n",
    "                print('loaded: ' + partition)\n",
    "            else:\n",
    "                for i in tqdm(range(0,len(self.df))):\n",
    "                    row = self.df.iloc[i]\n",
    "                    img_path = \"APPFL/examples/cfp_images/\" + row[\"file_path\"]\n",
    "                    image = Image.open(img_path).convert(\"RGB\")\n",
    "                    img_array = np.array(image)\n",
    "                    #take only the 224x224 center square of the image\n",
    "                    h, w, _ = img_array.shape\n",
    "                    top = (h - 224) // 2\n",
    "                    left = (w - 224) // 2\n",
    "                    center_crop = img_array[top:top+224, left:left+224]\n",
    "                    #convert to grayscale\n",
    "                    gray = np.dot(center_crop[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "                    gray_3ch = np.stack((gray,)*3, axis=-1).astype(np.uint8)\n",
    "                    self.preload.append(gray_3ch)\n",
    "                self.preload = np.asarray(self.preload)\n",
    "                np.save(npsavfn, self.preload)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = row[\"label_idx\"]\n",
    "        dm_severity = row[\"dm_severity\"]\n",
    "        \n",
    "        if len(self.preload) > 0:\n",
    "            image = Image.fromarray(self.preload[idx])\n",
    "        else:\n",
    "            img_path = \"APPFL/examples/cfp_images/\" + row[\"file_path\"]\n",
    "            # load the image\n",
    "            image = Image.open(img_path).convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "        # apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, dm_severity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "ZI55NEO_Pv7o"
   },
   "source": [
    "**4b) Transformation of all images, normalization to ImageNet statistics  Augmenting training images to have horizontal flips and rotations for online augementation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "302450a0-0e29-4897-8885-ed7f7ae6384a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining transformation of image\n",
    "# Augmenting training data to have horizontal flips and rotations\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally\n",
    "    T.RandomRotation(degrees=15),  # Randomly rotate images\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "ZI55NEO_Pv7o"
   },
   "source": [
    "**4c) Call the loader class with partition filepaths and transforms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "id": "a8e303f4-ee51-4913-ba75-86118b666f3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading datasets into memory for faster training\n",
    "train_dataset = AIREADIDataset_grayscalecrop(train_df, train_transform, preload=True)\n",
    "val_dataset   = AIREADIDataset_grayscalecrop(val_df, val_transform, preload=True)\n",
    "test_dataset  = AIREADIDataset_grayscalecrop(test_df, val_transform, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "0wLvKQOKVNKr"
   },
   "source": [
    "## 5. Model Building\n",
    "\n",
    "**5a) Set batch size and create dataloader instances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "ab4a9726-a2cf-40d2-88fc-c092a746af2e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define batch size for data loading, batch sie is the number of training examples used during one iteration of model training\n",
    "batch_size = 64\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# Create DataLoader instances for efficient batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "id": "ZI55NEO_Pv7o"
   },
   "source": [
    "**5b) Define device to use for training and inference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa1e923-276a-4774-81de-0bc467983534",
    "outputId": "3ef67d86-d139-4154-951e-b329e525f1d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the device (GPU if available, else CPU), if this says CPU please raise your hand\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "id": "ZI55NEO_Pv7o"
   },
   "source": [
    "**5c) Define methods used during model training, defines what to do each train step, validation inference, and plotting the learning curves.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "id": "4H-s58anWHzc"
   },
   "outputs": [],
   "source": [
    "# Methods to help with model training\n",
    "def train_step(model, dataloader, optimizer, criterion, device, batch_losses):\n",
    "    \"\"\"Performs a single training step over the dataset.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=True)\n",
    "\n",
    "    for batch_idx, (images, labels, _) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "        progress_bar.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_step(model, dataloader, criterion, device):\n",
    "    \"\"\"Performs a single validation step over the dataset.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Validating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, _) in enumerate(progress_bar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def plot_training_progress(batch_losses, train_accuracies, val_accuracies, epoch):\n",
    "    \"\"\"Plots the training loss and accuracy over epochs.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(batch_losses, label='Train Batch Loss', alpha=0.5, color='blue')\n",
    "    plt.xlabel('Iterations (Batches & Epochs)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epoch+2), train_accuracies, label='Train Accuracy', marker='o')\n",
    "    plt.plot(range(1, epoch+2), val_accuracies, label='Val Accuracy', marker='o')\n",
    "    plt.ylim([0.2, 1.05])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training & Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs):\n",
    "    \"\"\"Trains and validates the model over multiple epochs.\"\"\"\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    batch_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_step(model, train_loader, optimizer, criterion, device, batch_losses)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        val_loss, val_acc = validate_step(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\nEpoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "        plot_training_progress(batch_losses, train_accuracies, val_accuracies, epoch)\n",
    "\n",
    "    return train_accuracies, val_accuracies, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "id": "DoVk1ibyTle2"
   },
   "source": [
    "**5d) Defining model architecture: a pre-existing RESNET50 model architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will make the initializtion the same each time it is run for the same setting of parameters, just run once\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                         # Python built-in random\n",
    "    np.random.seed(seed)                      # NumPy\n",
    "    torch.manual_seed(seed)                   # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)             # PyTorch CUDA (if using GPU)\n",
    "    torch.cuda.manual_seed_all(seed)          # All CUDA devices (if using multi-GPU)\n",
    "\n",
    "set_seed(12)\n",
    "#Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "id": "38a1fc7b-6072-4ca2-9451-e8f449ca5577",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the ResNet50 model\n",
    "model = models.resnet50(weights=None)\n",
    "\n",
    "# Modify the last layer for our classification task\n",
    "# Changing to 4 classes as we have 4 devices to classify it into\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Transfer model to device (GPU or CPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "id": "DoVk1ibyTle2"
   },
   "source": [
    "**5e) Choose a cost function, an optimizer and set learning rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "id": "e8bf1388-f2c2-4279-b196-a2c2c8379bff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function, the function that we want to minimize to find the best assignment of labels \n",
    "criterion = nn.CrossEntropyLoss()  #CE quantifies how well a model's predicted probability distribution aligns with the true, or actual, probability distribution of the data\n",
    "\n",
    "#set the optimier and learning rate (lr), there are different mathemactical methods to minimize loss functions, the learning rate dictates how big a step you take toward the minima\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "62F7wDmIhfet"
   },
   "source": [
    "## 6. Running training: Call training function with desired number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "NPNFjd7HSsDJ",
    "outputId": "ac42b666-37bb-45c3-dfda-2994638b4b60"
   },
   "outputs": [],
   "source": [
    "#The number of eopch sets how many the model learns over the entire dataset in \n",
    "start = time.time()\n",
    "train_model(model=model, train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            num_epochs=24)\n",
    "print(\"Training time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "vsm-VL2hhrMr"
   },
   "source": [
    "## 7. Testing model: Perform inference with model on validation dataset\n",
    "\n",
    "**7a) We are saving the test set for the final model chosen, so we evaluate on the validation set for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- VAL ---------------------\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_dm_severity = []\n",
    "print(\"Evaluating on val set...\")\n",
    "if len(val_df) > 0:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, dm_severity in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_dm_severity.extend(dm_severity)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "    # Create a DataFrame to store results\n",
    "df_results_val1 = pd.DataFrame({\n",
    "    'true_device': all_labels,\n",
    "    'pred_device': all_preds,\n",
    "    'dm_severity': all_dm_severity\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "id": "0gw--B_VT683"
   },
   "source": [
    "**7b) Saving test set results to a dataframe for use below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "id": "L46bWxkSGngl"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store results\n",
    "df_results_val1 = pd.DataFrame({\n",
    "    'true_device': all_labels,\n",
    "    'pred_device': all_preds,\n",
    "    'dm_severity': all_dm_severity\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "j3UuCIOhiAnh"
   },
   "source": [
    "## 8. Evaluate model performace on the Validation Set\n",
    "\n",
    "**8a) Plot confusion matrix of device type for the val set.  This allows for interrogation of model performance on each class (device).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to plot a confusion matrix (cm)\n",
    "def plot_confusion_matrix(cm, device_names, title=\"Confusion Matrix\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', aspect='auto')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(device_names))\n",
    "    plt.xticks(tick_marks, device_names, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, device_names)\n",
    "\n",
    "    # Optionally annotate cells with counts\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",color=\"white\")\n",
    "                     #color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Predicted Device')\n",
    "    plt.ylabel('True Device')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices with confusion_matrix function from scikit-learn\n",
    "true_devs = df_results_val1['true_device'].values\n",
    "pred_devs = df_results_val1['pred_device'].values\n",
    "\n",
    "cm = confusion_matrix(true_devs, pred_devs)\n",
    "\n",
    "idx_to_device = {v: k for k, v in class_to_idx.items()}\n",
    "device_names = [idx_to_device[i] for i in sorted(idx_to_device.keys())]\n",
    "\n",
    "#calls function witten above\n",
    "plot_confusion_matrix(cm, device_names, title=f\"Device Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "j3UuCIOhiAnh"
   },
   "source": [
    "**8b) Plot Receiver-Operator Curve (ROC)**\n",
    "\n",
    "An ROC curve plots the rate of false positives versus the rate of true positives.  In our case, we just have one (FPR,TPR) pair and the (0,0) - > everything is predicted 0 and (1,1) points -> everything predicted 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_pred, class_labels):\n",
    "  \n",
    "  n_classes = len(np.unique(y_test))\n",
    "  y_test = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "  y_pred = label_binarize(y_pred, classes=np.arange(n_classes))\n",
    "\n",
    "  # Compute ROC curve and ROC area for each class\n",
    "  fpr = dict()\n",
    "  tpr = dict()\n",
    "  roc_auc = dict()\n",
    "  for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "  \n",
    "  # Compute micro-average ROC curve and ROC area\n",
    "  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "  # First aggregate all false positive rates\n",
    "  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "  # Then interpolate all ROC curves at this points\n",
    "  mean_tpr = np.zeros_like(all_fpr)\n",
    "  for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "  # Finally average it and compute AUC\n",
    "  mean_tpr /= n_classes\n",
    "\n",
    "  #fpr[\"macro\"] = all_fpr\n",
    "  #tpr[\"macro\"] = mean_tpr\n",
    "  #roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "  # Plot all ROC curves\n",
    "  plt.figure(figsize=(7,5))\n",
    "  lw = 2\n",
    "  plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "    label=\"Average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\", linestyle=\":\", linewidth=4,)\n",
    "\n",
    "  #plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "    #label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    #color=\"navy\", linestyle=\":\", linewidth=4,)\n",
    "\n",
    "  colors = cycle([\"aqua\", \"darkorange\", \"darkgreen\", \"yellow\", \"blue\"])\n",
    "  for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "        label=\" Class = {0} (area = {1:0.2f})\".format(device_names[i], roc_auc[i]),)\n",
    "\n",
    "  plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.0])\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "  plt.title(\"Receiver Operating Characteristic (ROC) curve\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(df_results_val1['true_device'].values,df_results_val1['pred_device'].values, device_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {
    "id": "j3UuCIOhiAnh"
   },
   "source": [
    "## 9. Improve model performace\n",
    "\n",
    "**9a) Let's explore a different optimizer and learning rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size for data loading\n",
    "batch_size = 64\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# Create DataLoader instances for efficient batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = models.resnet50(weights=None)\n",
    "# Modify the last layer for our classification task\n",
    "# Changing to 4 classes as we have 4 devices to classify it into\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "# Transfer model to device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#set the optimier and learning rate (lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=7e-6, weight_decay=1e-3)   #<- this is what we are changing!!\n",
    "\n",
    "start = time.time()\n",
    "train_model(model=model, train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            num_epochs=24)\n",
    "print(\"Training time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- VAL ---------------------\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_dm_severity = []\n",
    "print(\"Evaluating on val set...\")\n",
    "if len(val_df) > 0:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, dm_severity in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_dm_severity.extend(dm_severity)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "    # Create a DataFrame to store results\n",
    "df_results_val2 = pd.DataFrame({\n",
    "    'true_device': all_labels,\n",
    "    'pred_device': all_preds,\n",
    "    'dm_severity': all_dm_severity\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices with confusion_matrix function from scikit-learn\n",
    "true_devs = df_results_val2['true_device'].values\n",
    "pred_devs = df_results_val2['pred_device'].values\n",
    "cm = confusion_matrix(true_devs, pred_devs)\n",
    "\n",
    "idx_to_device = {v: k for k, v in class_to_idx.items()}\n",
    "device_names = [idx_to_device[i] for i in sorted(idx_to_device.keys())]\n",
    "\n",
    "#calls function witten above\n",
    "plot_confusion_matrix(cm, device_names, title=f\"Device Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ROC curve\n",
    "plot_roc_curve(df_results_val2['true_device'].values,df_results_val2['pred_device'].values, device_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "id": "j3UuCIOhiAnh"
   },
   "source": [
    "**9b) Second the weight initialiation will be changed by using the pretrained weights (ImageNet) for the ResNet50.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size for data loading\n",
    "batch_size = 64\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# Create DataLoader instances for efficient batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = models.resnet50(weights = ResNet50_Weights.IMAGENET1K_V2) #<- this is what we are changing!!\n",
    "# Modify the last layer for our classification task\n",
    "# Changing to 4 classes as we have 4 devices to classify it into\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "# Transfer model to device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#set the optimier and learning rate (lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=7e-6, weight_decay=1e-3)\n",
    "\n",
    "start = time.time()\n",
    "train_model(model=model, train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            num_epochs=30)\n",
    "print(\"Training time: \", time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- VAL ---------------------\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_dm_severity = []\n",
    "print(\"Evaluating on val set...\")\n",
    "if len(val_df) > 0:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, dm_severity in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_dm_severity.extend(dm_severity)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "    # Create a DataFrame to store results\n",
    "df_results_val3 = pd.DataFrame({\n",
    "    'true_device': all_labels,\n",
    "    'pred_device': all_preds,\n",
    "    'dm_severity': all_dm_severity\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices with confusion_matrix function from scikit-learn\n",
    "true_devs = df_results_val3['true_device'].values\n",
    "pred_devs = df_results_val3['pred_device'].values\n",
    "cm = confusion_matrix(true_devs, pred_devs)\n",
    "\n",
    "idx_to_device = {v: k for k, v in class_to_idx.items()}\n",
    "device_names = [idx_to_device[i] for i in sorted(idx_to_device.keys())]\n",
    "\n",
    "#calls function witten above\n",
    "plot_confusion_matrix(cm, device_names, title=f\"Device Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ROC curve\n",
    "plot_roc_curve(df_results_val3['true_device'].values,df_results_val3['pred_device'].values, device_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {
    "id": "j3UuCIOhiAnh"
   },
   "source": [
    "## 10. Choose a model to evaluate on the test data\n",
    "\n",
    "**The model has not seen these images so this is the least biased way to evaluate a model's perfroamce.  But you can only run one model on your test set, so choose carefully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_dm_severity = []\n",
    "print(\"Evaluating on test set...\")\n",
    "if len(test_df) > 0:\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, dm_severity in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_dm_severity.extend(dm_severity)\n",
    "\n",
    "    test_loss /= test_total\n",
    "    test_acc = test_correct / test_total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    # Create a DataFrame to store results\n",
    "df_results_test = pd.DataFrame({\n",
    "    'true_device': all_labels,\n",
    "    'pred_device': all_preds,\n",
    "    'dm_severity': all_dm_severity\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices with confusion_matrix function from scikit-learn\n",
    "true_devs = df_results_test['true_device'].values\n",
    "pred_devs = df_results_test['pred_device'].values\n",
    "cm = confusion_matrix(true_devs, pred_devs)\n",
    "\n",
    "idx_to_device = {v: k for k, v in class_to_idx.items()}\n",
    "device_names = [idx_to_device[i] for i in sorted(idx_to_device.keys())]\n",
    "\n",
    "#calls function witten above\n",
    "plot_confusion_matrix(cm, device_names, title=f\"Device Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ROC curve\n",
    "plot_roc_curve(df_results_test['true_device'].values,df_results_test['pred_device'].values, device_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total time: \", time.time() - start_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {
    "id": "j3UuCIOhiAnh"
   },
   "source": [
    "## 11. Sandbox: Explore hyperparameter settings.\n",
    "\n",
    "**This code was set up for you to explore what happens when you change hyperparameters.**\n",
    "\n",
    "**Things you could try:**\n",
    "\n",
    "1. Change data augmentation parameters.\n",
    "2. Change batch size (warning you may run into memory constraints)\n",
    "3. Change the initialization seed to any number\n",
    "4. Change the initialization of the weights (model = models.resnet50(weights = ResNet50_Weights.IMAGENET1K_V2))\n",
    "5. Change the optimizer and/or learning rate (https://pytorch.org/docs/main/optim.html)\n",
    "6. Change the number of epocs (you want to see model convergence, training curve is flat at end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining transformation of image\n",
    "# Augmenting training data to have horizontal flips and rotations\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally\n",
    "    T.RandomRotation(degrees=15),  # Randomly rotate images\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Loading datasets into memory for faster training\n",
    "train_dataset = AIREADIDataset_grayscalecrop(train_df, train_transform, preload=True)\n",
    "val_dataset   = AIREADIDataset_grayscalecrop(val_df, val_transform, preload=True)\n",
    "test_dataset  = AIREADIDataset_grayscalecrop(test_df, val_transform, preload=True)\n",
    "\n",
    "# Define batch size for data loading\n",
    "batch_size = 64\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# Create DataLoader instances for efficient batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, worker_init_fn=lambda _: np.random.seed(42))\n",
    "\n",
    "# Define the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#this will make the initializtion the same each time it is run for the same setting of parameters\n",
    "\n",
    "set_seed(12)\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = models.resnet50(weights=None)\n",
    "# Modify the last layer for our classification task\n",
    "# Changing to 4 classes as we have 4 devices to classify it into\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "# Transfer model to device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#set the optimier and learning rate (lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=.5)\n",
    "\n",
    "start = time.time()\n",
    "train_model(model=model, train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            num_epochs=24)\n",
    "print(\"Training time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcKoyEe21Zbj",
    "outputId": "65391879-5423-4264-b7b6-74005b74ed4d"
   },
   "outputs": [],
   "source": [
    "# clean GPU memory\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
